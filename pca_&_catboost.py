# -*- coding: utf-8 -*-
"""PCA & Catboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VK2SZOFJ8S90u8juN64ah1nF94u40n4c

# **Abstract**

Name: Mustafa Atif Ibrahim

  Email: mibra004@odu.edu

  Degree: M.S. Data Science & Analytics
  
  Portfolio: https://mibra004.github.io/
"""

!pip install catboost

"""# Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report , precision_recall_curve, average_precision_score
from catboost import CatBoostClassifier
from scipy.stats import zscore
from scipy.stats import spearmanr
from scipy.cluster import hierarchy
import seaborn as sns
from collections import defaultdict
# %matplotlib inline

"""# Data Cleaning"""

ddos = pd.read_csv("cic_ids_2019_ddos.csv")
ddos.tail()

def replace_infinity_with_mean(df):
    inf_columns = [c for c in df.columns if df[df[c] == np.inf][c].count() > 0]
    for col in inf_columns:
        df[col].replace([np.inf, -np.inf], np.nan, inplace=True)
        mean = df[col].mean()
        df[col].fillna(mean, inplace=True)
    return df

def replace_negative_values_with_mean(df):
    numeric_cols = df.select_dtypes(include=[np.number]).columns.values
    
    columns = [c for c in numeric_cols if df[df[c] < 0][c].count() > 0]
    for col in columns:
        mask = df[col] < 0
        df.loc[mask, col] = np.nan
        mean = df[col].mean()
        df[col].fillna(mean, inplace=True)
    return df


ddos = replace_infinity_with_mean(ddos)
ddos = replace_negative_values_with_mean(ddos)

# ddos.info()
ddos.shape

X = ddos.drop(columns= [ ' Label' , ' Destination Port' ])
y = ddos [[' Label' ]]
X.shape

stats = X.describe()
std = stats.loc['std']
features_no_variance = std[std == 0.0].index
pd.Series(features_no_variance).sort_values()

X= X.drop(columns=features_no_variance)
#X.info()
X.shape

fig,axes=plt.subplots(1,1,figsize=(12,6))
boxplot = X.boxplot()
X.describe()

z_scores = zscore(X.iloc[:,[0,1,2]])
abs_z_scores = np.abs(z_scores)
filtered_entries = (abs_z_scores < 0.2).all(axis=1)
new_df = X[filtered_entries]

fig,axes=plt.subplots(1,1,figsize=(12,6))
boxplot = new_df.boxplot(column='Total Length of Fwd Packets')

fig,axes=plt.subplots(1,1,figsize=(12,6))
boxplot = new_df.boxplot(column=' Flow Duration')

"""# Feature Selection"""

cluster_threshold = 1

corr = spearmanr(X).correlation
corr_linkage = hierarchy.ward(corr)

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(25, 40))

sns.heatmap(corr, xticklabels=X.columns, yticklabels=X.columns, linewidths=.5, cmap=sns.diverging_palette(620, 10, as_cmap=True), ax=ax1)

dendro = hierarchy.dendrogram(corr_linkage, labels=X.columns, ax=ax2, leaf_rotation=90)
dendro_idx = np.arange(0, len(dendro['ivl']))
ax2.plot([0, 1000], [cluster_threshold, cluster_threshold], ':r')
plt.show()

cluster_ids = hierarchy.fcluster(corr_linkage, cluster_threshold, criterion='distance')
cluster_id_to_feature_ids = defaultdict(list)

for idx, cluster_id in enumerate(cluster_ids):
    cluster_id_to_feature_ids[cluster_id].append(idx)
selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]

selected_features = X.columns[selected_features].tolist()

print('Selected features:')
pd.Series(selected_features)

# X = X[selected_features]

X = X[selected_features]
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
X_train

sc = StandardScaler()
train_df = sc.fit_transform(X_train)
test_df = sc.transform(X_test)
train_df

"""# PCA"""

pca = PCA(n_components=2)
X_train = pca.fit_transform(train_df)
X_test = pca.transform(test_df)

explained_variance = pca.explained_variance_ratio_
explained_variance

SOK = np.round(explained_variance, decimals=2)
SOK

KOT = dict(zip(X, SOK))

KOT_sorted_keys = sorted(KOT, key=KOT.get, reverse=True)

for r in KOT_sorted_keys:
    print (r, KOT[r])

    KOT

y_train.value_counts().plot(kind="barh")

"""# Catboost"""

# set the metric for evaluation
model = CatBoostClassifier(eval_metric='Accuracy', random_seed=42)
model.fit(X_train, y_train)
print('Test set score:', model.get_best_score())

y_pred = model.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

model = CatBoostClassifier(iterations=10, depth=2, loss_function='Logloss')
model.fit(X_train, y_train)
print('Test set score:', model.get_best_score())

y_pred = model.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# False Positive is 38, True Negative is 62

from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(confusion_matrix, annot=True)